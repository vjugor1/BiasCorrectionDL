{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceil(v):\n",
    "        if v == int(v): return int(v)\n",
    "        else: return int(v+1)\n",
    "in_ch = 3\n",
    "out_ch = 3\n",
    "ncvar=46\n",
    "norm_chs = 4 * ceil(out_ch/4)\n",
    "use_sam = True\n",
    "use_cam = True\n",
    "use_ele = True\n",
    "ret_sam = False\n",
    "scale = 2\n",
    "cvar_ch=8\n",
    "relu_a=0.01\n",
    "stage_chs=(256, 128, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel attention module \n",
    "class CAM(torch.nn.Module):\n",
    "    def __init__(self, in_ch, relu_a=0.01, r=2):\n",
    "        super().__init__()\n",
    "        self.mlp_ops = [\n",
    "            torch.nn.Linear(in_ch, in_ch//r),\n",
    "            torch.nn.LeakyReLU(negative_slope=relu_a), \n",
    "            torch.nn.Linear(in_ch//r, in_ch),\n",
    "        ]\n",
    "        \n",
    "        self.amlp_layer = torch.nn.Sequential(*self.mlp_ops)\n",
    "        self.out_act    = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, ret_att=False):\n",
    "        _max_out, _ = torch.max(x, 2, keepdim=False)\n",
    "        _max_out, _ = torch.max(_max_out, -1, keepdim=False)\n",
    "        \n",
    "        _avg_out    = torch.mean(x, 2, keepdim=False)\n",
    "        _avg_out    = torch.mean(_avg_out, -1, keepdim=False)\n",
    "        \n",
    "        _mlp_max    = _max_out\n",
    "        for layer in self.amlp_layer:\n",
    "            _mlp_max = layer(_mlp_max)\n",
    "            \n",
    "        _mlp_avg    = _avg_out\n",
    "        for layer in self.amlp_layer:\n",
    "            _mlp_avg = layer(_mlp_avg)\n",
    "            \n",
    "        _attention = self.out_act(_mlp_avg + _mlp_max)\n",
    "        _attention = _attention.unsqueeze(-1)\n",
    "        _attention = _attention.unsqueeze(-1)\n",
    "   \n",
    "        if ret_att:\n",
    "            return _attention, _attention * x\n",
    "        else:\n",
    "            return _attention * x\n",
    "\n",
    "\n",
    "# Spatial attention module \n",
    "class SAM(torch.nn.Module):\n",
    "    def __init__(self, in_ch, relu_a=0.01):\n",
    "        super().__init__()\n",
    "        self.cnn_ops = [\n",
    "            torch.nn.Conv2d(in_channels=2, out_channels=1, \\\n",
    "                            kernel_size=7, padding=3),\n",
    "            torch.nn.Sigmoid(), ] # use Sigmoid to norm to [0, 1]\n",
    "        \n",
    "        self.attention_layer = torch.nn.Sequential(*self.cnn_ops)\n",
    "        \n",
    "    def forward(self, x, ret_att=False):\n",
    "        _max_out, _ = torch.max(x, 1, keepdim=True)\n",
    "        _avg_out    = torch.mean(x, 1, keepdim=True)\n",
    "        _out = torch.cat((_max_out, _avg_out), dim=1)\n",
    "        _attention = _out\n",
    "        for layer in self.attention_layer:\n",
    "            _attention = layer(_attention)\n",
    "           \n",
    "        if ret_att:\n",
    "            return _attention, _attention * x\n",
    "        else:\n",
    "            return _attention * x\n",
    "\n",
    "\n",
    "class inception_box(torch.nn.Module):\n",
    "    def __init__(self, in_ch, o_ch, relu_a=0.01):\n",
    "        super().__init__()\n",
    "        assert o_ch % 4 == 0\n",
    "        self.conv1b1_ops = [\n",
    "            torch.nn.Conv2d(in_channels=in_ch, out_channels=o_ch//4, kernel_size=1, \\\n",
    "                            stride=1, padding=0),\n",
    "            torch.nn.LeakyReLU(negative_slope=relu_a), ]\n",
    "        \n",
    "        self.conv3b3_ops = [\n",
    "            torch.nn.Conv2d(in_channels=in_ch, out_channels=o_ch//4, kernel_size=1, \\\n",
    "                            stride=1, padding=0),\n",
    "            torch.nn.LeakyReLU(negative_slope=relu_a), \n",
    "            torch.nn.Conv2d(in_channels=o_ch//4, out_channels=o_ch//4, kernel_size=3, \\\n",
    "                            stride=1, padding=1),\n",
    "            torch.nn.LeakyReLU(negative_slope=relu_a), ]\n",
    "        \n",
    "        self.conv5b5_ops = [\n",
    "            torch.nn.Conv2d(in_channels=in_ch, out_channels=o_ch//4, kernel_size=1, \\\n",
    "                            stride=1, padding=0),\n",
    "            torch.nn.LeakyReLU(negative_slope=relu_a), \n",
    "            torch.nn.Conv2d(in_channels=o_ch//4, out_channels=o_ch//4, kernel_size=5, \\\n",
    "                            stride=1, padding=2),\n",
    "            torch.nn.LeakyReLU(negative_slope=relu_a), ]\n",
    "        \n",
    "        self.maxpool_ops = [\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.Conv2d(in_channels=in_ch, out_channels=o_ch//4, kernel_size=1, \\\n",
    "                            stride=1, padding=0),\n",
    "            torch.nn.LeakyReLU(negative_slope=relu_a), ]\n",
    "        \n",
    "        self.conv1b1 = torch.nn.Sequential(*self.conv1b1_ops)\n",
    "        self.conv3b3 = torch.nn.Sequential(*self.conv3b3_ops)\n",
    "        self.conv5b5 = torch.nn.Sequential(*self.conv5b5_ops)\n",
    "        self.maxpool = torch.nn.Sequential(*self.maxpool_ops)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        _out_conv1b1 = x\n",
    "        for layer in self.conv1b1:\n",
    "            _out_conv1b1 = layer(_out_conv1b1)\n",
    "            \n",
    "        _out_conv3b3 = x\n",
    "        for layer in self.conv3b3:\n",
    "            _out_conv3b3 = layer(_out_conv3b3)\n",
    "            \n",
    "        _out_conv5b5 = x\n",
    "        for layer in self.conv5b5:\n",
    "            _out_conv5b5 = layer(_out_conv5b5)\n",
    "            \n",
    "        _out_maxpool = x\n",
    "        for layer in self.conv1b1:\n",
    "            _out_maxpool = layer(_out_maxpool)\n",
    "            \n",
    "        return torch.cat([_out_conv1b1, _out_conv3b3, _out_conv5b5, _out_maxpool], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_norm_ops = [\n",
    "    torch.nn.Conv2d(in_channels=out_ch, out_channels=norm_chs, \\\n",
    "                    kernel_size=1, stride=1, padding=0),\n",
    "    torch.nn.BatchNorm2d(num_features=norm_chs),\n",
    "    torch.nn.LeakyReLU(negative_slope=relu_a), ]\n",
    "\n",
    "up1_ops = [\n",
    "    torch.nn.ConvTranspose2d(in_channels=stage_chs[0]+cvar_ch*ncvar, out_channels=stage_chs[0], \\\n",
    "                                    kernel_size=2, stride=2, padding=0),\n",
    "    torch.nn.LeakyReLU(negative_slope=0.01), ]\n",
    "\n",
    "up2_ops = [\n",
    "    torch.nn.ConvTranspose2d(in_channels=stage_chs[1], out_channels=stage_chs[1], \\\n",
    "                                    kernel_size=2, stride=2, padding=0),\n",
    "    torch.nn.LeakyReLU(negative_slope=0.01), ]\n",
    "    \n",
    "if use_ele:\n",
    "    ele_ops = [\n",
    "        torch.nn.Conv2d(in_channels=1, out_channels=4, \\\n",
    "                        kernel_size=3, stride=1, padding=1),\n",
    "        torch.nn.LeakyReLU(negative_slope=0.01), \n",
    "        torch.nn.Conv2d(in_channels=4, out_channels=8, \\\n",
    "                        kernel_size=3, stride=1, padding=1),\n",
    "        torch.nn.LeakyReLU(negative_slope=0.01), ]\n",
    "\n",
    "out_ops = [\n",
    "    torch.nn.Conv2d(in_channels=stage_chs[2], out_channels=4, \\\n",
    "                    kernel_size=3, stride=1, padding=1),\n",
    "    torch.nn.BatchNorm2d(num_features=4),\n",
    "    torch.nn.LeakyReLU(negative_slope=0.01), \n",
    "    torch.nn.Conv2d(in_channels=4, out_channels=out_ch, # was out_channels=1,\n",
    "                    kernel_size=3, stride=1, padding=1),]\n",
    "\n",
    "\n",
    "cvar_inceps = [torch.nn.ModuleList([inception_box(in_ch=1, o_ch=cvar_ch), \\\n",
    "                        inception_box(in_ch=cvar_ch, o_ch=cvar_ch), \\\n",
    "                        inception_box(in_ch=cvar_ch, o_ch=cvar_ch), \\\n",
    "                        inception_box(in_ch=cvar_ch, o_ch=cvar_ch)]) for _ in range(ncvar)]\n",
    "cvar_inceps = torch.nn.ModuleList(cvar_inceps)\n",
    "\n",
    "ich_layers = torch.nn.Sequential(*in_norm_ops)\n",
    "\n",
    "p1_inception1 = inception_box(in_ch = norm_chs, o_ch=stage_chs[0])\n",
    "p1_inception2 = inception_box(in_ch = stage_chs[0], o_ch = stage_chs[0])\n",
    "p1_inception3 = inception_box(in_ch = stage_chs[0], o_ch = stage_chs[0])\n",
    "p1_inception4 = inception_box(in_ch = stage_chs[0], o_ch = stage_chs[0])\n",
    "up1_layers    = torch.nn.Sequential(*up1_ops)\n",
    "\n",
    "p2_inception1 = inception_box(in_ch = stage_chs[0], o_ch = stage_chs[1])\n",
    "p2_inception2 = inception_box(in_ch = stage_chs[1], o_ch = stage_chs[1])\n",
    "p2_inception3 = inception_box(in_ch = stage_chs[1], o_ch = stage_chs[1])\n",
    "p2_inception4 = inception_box(in_ch = stage_chs[1], o_ch = stage_chs[1])\n",
    "up2_layers    = torch.nn.Sequential(*up2_ops)\n",
    "\n",
    "if use_cam:\n",
    "    up1_cam = CAM(in_ch = stage_chs[0] + cvar_ch*ncvar)\n",
    "    up2_cam = CAM(in_ch = stage_chs[1])\n",
    "\n",
    "if use_sam:\n",
    "    up1_sam = SAM(in_ch = stage_chs[0])\n",
    "    up2_sam = SAM(in_ch = stage_chs[1])\n",
    "\n",
    "if use_ele:\n",
    "    ele_layers = torch.nn.Sequential(*ele_ops)\n",
    "    p3_inception1 = inception_box(in_ch = 8+stage_chs[1], o_ch = stage_chs[2])\n",
    "else:\n",
    "    p3_inception1 = inception_box(in_ch = stage_chs[1], o_ch = stage_chs[2])\n",
    "p3_inception2 = inception_box(in_ch = stage_chs[2], o_ch = stage_chs[2])\n",
    "p3_inception3 = inception_box(in_ch = stage_chs[2], o_ch = stage_chs[2])\n",
    "p3_inception4 = inception_box(in_ch = stage_chs[2], o_ch = stage_chs[2])\n",
    "out_layers = torch.nn.Sequential(*out_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(64, 49, 32, 64)\n",
    "elev = torch.randn(64, 1, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional variables as list of tensors\n",
    "cvars = [x[...,i:i+1,:, :] for i in range(out_ch, x.shape[1])]\n",
    "x = x[...,:out_ch,:, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(cvars) == len(cvar_inceps)\n",
    "cvar_outs = []\n",
    "for _cf, cvar in zip(cvar_inceps, cvars):\n",
    "    _tmp = cvar\n",
    "    for _f in _cf:\n",
    "        _tmp = _f(_tmp)\n",
    "    cvar_outs.append(_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 8, 32, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvar_outs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 32, 64])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tmp = x\n",
    "for layer in ich_layers:\n",
    "    out_tmp = layer(out_tmp) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 32, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tmp = p1_inception1(out_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 32, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 32, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp = p1_inception2(out_tmp)\n",
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 32, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp = p1_inception3(out_tmp)\n",
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 32, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp = p1_inception4(out_tmp)\n",
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_sam: # apply spatial attention \n",
    "    if ret_sam:\n",
    "        atten1, out_tmp = up1_sam(out_tmp, ret_att=True) \n",
    "    else:\n",
    "        out_tmp = up1_sam(out_tmp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 32, 64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tmp = torch.cat([out_tmp,] + cvar_outs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 8, 32, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvar_outs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 624, 32, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cam:\n",
    "    out_tmp = up1_cam(out_tmp) # apply channel attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 624, 32, 64])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in up1_layers:\n",
    "    out_tmp = layer(out_tmp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 64, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128, 64, 128])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp = p2_inception1(out_tmp)\n",
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128, 64, 128])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp = p2_inception2(out_tmp)\n",
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128, 64, 128])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp = p2_inception3(out_tmp)\n",
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128, 64, 128])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp = p2_inception4(out_tmp)\n",
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cam:\n",
    "    out_tmp = up2_cam(out_tmp) # apply channel attention \n",
    "    \n",
    "if use_sam: # apply spatial attention \n",
    "    if ret_sam:\n",
    "        atten2, out_tmp = up2_sam(out_tmp, ret_att=True) \n",
    "    else:\n",
    "        out_tmp = up2_sam(out_tmp) \n",
    "\n",
    "for layer in up2_layers:\n",
    "    out_tmp = layer(out_tmp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128, 128, 256])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if elev is not None:\n",
    "    ele_tmp = elev\n",
    "    for layer in ele_layers:\n",
    "        ele_tmp = layer(ele_tmp)  \n",
    "    out_tmp = torch.cat([out_tmp, ele_tmp], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 136, 128, 256])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 128, 256])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp = p3_inception1(out_tmp)\n",
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 128, 256])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp = p3_inception2(out_tmp)\n",
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 128, 256])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp = p3_inception3(out_tmp)\n",
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 128, 256])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp = p3_inception4(out_tmp)\n",
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 4, 128, 256])\n",
      "torch.Size([64, 4, 128, 256])\n",
      "torch.Size([64, 4, 128, 256])\n",
      "torch.Size([64, 3, 128, 256])\n"
     ]
    }
   ],
   "source": [
    "for layer in out_layers:\n",
    "    out_tmp = layer(out_tmp)\n",
    "    print(out_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 128, 256])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp[:,:1,:, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = torch.randn(64, 3, 1024, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations = [\n",
    "    torch.nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1),\n",
    "    torch.nn.LeakyReLU(0.2), ]\n",
    "\n",
    "# Intermediate layers (C128-C256-C512-C512)\n",
    "out_chs = (128, 256, 512, 512)\n",
    "in_chs = (64, ) + out_chs[:-1]\n",
    "for ic, oc in zip(in_chs, out_chs):\n",
    "    operations += [\n",
    "        torch.nn.Conv2d(in_channels=ic, out_channels=oc, kernel_size=4, stride=2, padding=1),\n",
    "        torch.nn.BatchNorm2d(oc),\n",
    "        torch.nn.LeakyReLU(0.2), ]\n",
    "\n",
    "# Global Average Pooling\n",
    "global_pool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "# Output layer that outputs binary logits\n",
    "fc_layers = nn.Sequential(\n",
    "            nn.Linear(out_chs[-1], out_chs[-1] // 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(out_chs[-1] // 4, 1)\n",
    "        )\n",
    "\n",
    "layers = torch.nn.Sequential(*operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 512, 32, 64])\n",
      "torch.Size([64, 512, 1, 1])\n",
      "torch.Size([64, 512])\n",
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "test = layers(tst)\n",
    "print(test.shape)\n",
    "test = global_pool(test)\n",
    "print(test.shape)\n",
    "test = test.view(x.size(0), -1)\n",
    "print(test.shape)\n",
    "test = fc_layers(test)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 2, 4])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc_out_size= (32, 1, 2, 4)\n",
    "true_label  = torch.ones (dsc_out_size)\n",
    "false_label = torch.zeros(dsc_out_size)\n",
    "disc_label  = torch.cat((true_label, false_label), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 2, 4])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(100.)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.BCELoss()(torch.ones(1,1), torch.zeros(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = layers(out_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tst2 = layers(out_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.7115)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst2.mean().log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    advs_loss = 0 - layers(out_tmp).mean().log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advs_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 4, 4])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1540, -0.1572,  0.2223, -0.0017],\n",
       "         [ 0.0184,  0.0606,  0.2462, -0.5188]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 2, 4])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4419, 0.4992, 0.3913, 0.4340],\n",
       "         [0.4333, 0.5574, 0.5085, 0.5064]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ceil(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_norm_ops = [\n",
    "    torch.nn.Conv2d(in_channels=in_ch, out_channels=norm_chs,\n",
    "                    kernel_size=1, stride=1, padding=0),\n",
    "    torch.nn.BatchNorm2d(num_features=norm_chs),\n",
    "    torch.nn.LeakyReLU(negative_slope=relu_a), ]\n",
    "\n",
    "in_norm_layers = torch.nn.Sequential(*in_norm_ops)\n",
    "\n",
    "up_layers = torch.nn.ModuleList()\n",
    "inception_layers = torch.nn.ModuleList()\n",
    "\n",
    "current_in_ch = norm_chs\n",
    "for i in range(len(stage_chs)):\n",
    "    up_ops = [\n",
    "        torch.nn.ConvTranspose2d(in_channels=current_in_ch, out_channels=stage_chs[i],\n",
    "                                    kernel_size=2, stride=2, padding=0),\n",
    "        torch.nn.LeakyReLU(negative_slope=relu_a), ]\n",
    "    up_layers.append(torch.nn.Sequential(*up_ops))\n",
    "\n",
    "    inception_block = torch.nn.Sequential(\n",
    "        inception_box(in_ch=stage_chs[i], o_ch=stage_chs[i]),\n",
    "        inception_box(in_ch=stage_chs[i], o_ch=stage_chs[i]),\n",
    "        inception_box(in_ch=stage_chs[i], o_ch=stage_chs[i]),\n",
    "        inception_box(in_ch=stage_chs[i], o_ch=stage_chs[i])\n",
    "    )\n",
    "    inception_layers.append(inception_block)\n",
    "    current_in_ch = stage_chs[i]\n",
    "\n",
    "if use_ele:\n",
    "    ele_ops = [\n",
    "        torch.nn.Conv2d(in_channels=1, out_channels=4,\n",
    "                        kernel_size=3, stride=1, padding=1),\n",
    "        torch.nn.LeakyReLU(negative_slope=0.01),\n",
    "        torch.nn.Conv2d(in_channels=4, out_channels=8,\n",
    "                        kernel_size=3, stride=1, padding=1),\n",
    "        torch.nn.LeakyReLU(negative_slope=0.01), ]\n",
    "    ele_layers = torch.nn.Sequential(*ele_ops)\n",
    "    current_in_ch += 8\n",
    "\n",
    "out_ops = [\n",
    "    torch.nn.Conv2d(in_channels=current_in_ch, out_channels=4,\n",
    "                    kernel_size=3, stride=1, padding=1),\n",
    "    torch.nn.BatchNorm2d(num_features=4),\n",
    "    torch.nn.LeakyReLU(negative_slope=0.01),\n",
    "    torch.nn.Conv2d(in_channels=4, out_channels=in_ch,\n",
    "                    kernel_size=3, stride=1, padding=1), ]\n",
    "out_layers = torch.nn.Sequential(*out_ops)\n",
    "\n",
    "cvar_inceps = [torch.nn.ModuleList([inception_box(in_ch=1, o_ch=cvar_ch),\n",
    "                                            inception_box(in_ch=cvar_ch, o_ch=cvar_ch),\n",
    "                                            inception_box(in_ch=cvar_ch, o_ch=cvar_ch),\n",
    "                                            inception_box(in_ch=cvar_ch, o_ch=cvar_ch)]) for _ in range(ncvar)]\n",
    "cvar_inceps = torch.nn.ModuleList(cvar_inceps)\n",
    "\n",
    "if use_cam:\n",
    "    cam_layers = torch.nn.ModuleList([CAM(in_ch=stage_chs[i] + cvar_ch * ncvar if i == 0 else stage_chs[i]) for i in range(len(stage_chs))])\n",
    "\n",
    "if use_sam:\n",
    "    sam_layers = torch.nn.ModuleList([SAM(in_ch=stage_chs[i]) for i in range(len(stage_chs))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional variables as list of tensors\n",
    "cvars = [x[..., i:i + 1, :, :] for i in range(in_ch, x.shape[1])]\n",
    "x = x[..., :in_ch, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        # input layer\n",
    "        self.operations = [\n",
    "            torch.nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=4, stride=2, padding=1),\n",
    "            torch.nn.LeakyReLU(0.2), ]  \n",
    "        # C128-C256-C512-C512\n",
    "        out_chs = (128, 256, 512, 512, )\n",
    "        in_chs  = (64, ) + out_chs[:-1]\n",
    "        for ic, oc in zip(in_chs, out_chs):\n",
    "            self.operations += [\n",
    "                torch.nn.Conv2d(in_channels=ic, out_channels=oc, kernel_size=4, \\\n",
    "                                stride=2, padding=1),\n",
    "                torch.nn.BatchNorm2d(oc),\n",
    "                torch.nn.LeakyReLU(0.2), ]\n",
    "            \n",
    "        # output layers\n",
    "        self.operations += [\n",
    "            torch.nn.Conv2d(in_channels=out_chs[-1], out_channels=1, kernel_size=4, stride=2, padding=1),\n",
    "            # torch.nn.Sigmoid(),  # comment this line for BCEWithLogitsLoss\n",
    "            ]\n",
    "        \n",
    "        self.layers = torch.nn.Sequential(*self.operations)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = discModel(in_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 32, 64])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(cvars) == len(cvar_inceps)\n",
    "cvar_outs = []\n",
    "for _cf, cvar in zip(cvar_inceps, cvars):\n",
    "    _tmp = cvar\n",
    "    for _f in _cf:\n",
    "        _tmp = _f(_tmp)\n",
    "    cvar_outs.append(_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 8, 32, 64])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvar_outs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 32, 64])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 4, 32, 64])\n",
      "torch.Size([64, 4, 32, 64])\n",
      "torch.Size([64, 4, 32, 64])\n"
     ]
    }
   ],
   "source": [
    "out_tmp = x\n",
    "for layer in in_norm_layers:\n",
    "    out_tmp = layer(out_tmp)\n",
    "    print(out_tmp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 32, 64])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(up_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(up_layers)):\n",
    "    out_tmp = inception_layers[i](out_tmp)\n",
    "    print(out_tmp.shape)\n",
    "    if use_sam:\n",
    "        if ret_sam:\n",
    "            atten, out_tmp = sam_layers[i](out_tmp, ret_att=True)\n",
    "        else:\n",
    "            out_tmp = sam_layers[i](out_tmp)\n",
    "\n",
    "    out_tmp = torch.cat([out_tmp] + cvar_outs, 1)  # concat cvars\n",
    "\n",
    "    if use_cam:\n",
    "        out_tmp = cam_layers[i](out_tmp)  # apply channel attention\n",
    "\n",
    "    out_tmp = up_layers[i](out_tmp)\n",
    "    print(out_tmp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if elev is not None:\n",
    "    ele_tmp = elev\n",
    "    for layer in ele_layers:\n",
    "        ele_tmp = layer(ele_tmp)\n",
    "    out_tmp = torch.cat([out_tmp, ele_tmp], 1)\n",
    "\n",
    "out_tmp = out_layers(out_tmp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bias_correction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
