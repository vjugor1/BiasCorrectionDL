base_dir: "/app/data/experiments/downscaling-ERA-ERA"

data:
  low_res_dir: "/app/data/ClimateLearn/processed/weatherbench/era5/5.625deg"
  high_res_dir: "/app/data/ClimateLearn/processed/weatherbench/era5/2.8125deg"
  subsample: 1
  batch_size: 32
  buffer_size: 2000
  num_workers: 2
  # Available variables: 
  # "land_sea_mask", "orography", "latitude", "toa_incident_solar_radiation",
  # "2m_temperature", "10m_u_component_of_wind", "10m_v_component_of_wind",
  # "geopotential", "temperature", "relative_humidity", "specific_humidity",
  # "u_component_of_wind", "v_component_of_wind"
  # in_variables: ["2m_temperature", "land_sea_mask", "orography", "lattitude", "10m_u_component_of_wind", "10m_v_component_of_wind"]
  in_variables: ["2m_temperature", "land_sea_mask", "orography", "lattitude", "toa_incident_solar_radiation", "10m_u_component_of_wind", "10m_v_component_of_wind", "geopotential", "temperature", "relative_humidity", "specific_humidity", "u_component_of_wind", "v_component_of_wind"]
  # Output variables to predict. Options are: "2m_temperature", "geopotential_500", "temperature_850"
  out_variables: ["2m_temperature", "geopotential_500", "temperature_850", "10m_u_component_of_wind", "10m_v_component_of_wind"]

model:
  # Model architecture options: "resnet", "unet", "vit", "samvit", "ynet", "deepsd", "diffusion", "dcgan", "edrn", "esrgan"
  architecture: "esrgan"
  # Upsampling method options: "bilinear", "bicubic", "unet_upsampling", "unet_upsampling_bilinear", "none"
  # NOTE: Some models (ynet, deepsd, diffusion, dcgan, edrn) do not support input upsampling, so they need this parameter set "none"
  upsampling: "bilinear"

training:
  summary_depth: 1
  max_epochs: 200
  patience: 5
  learning_rate: 3e-4
  weight_decay: 1e-5
  betas: [0.9, 0.99]
  warmup_epochs: 5
  train_loss: ["mse"]
  perceptual_hp:        #works only with single gpu; total loss is content(pred,target) + feature_coeff * feature_loss + gram_coeff * gram_loss
    feature_coeff: 0.01 #coefficient before \| phi_{relu_n}(pred) - phi_{relu_n}(target)) \|_2^2
    gram_coeff: 0.01    #coefficient before \| phi_{relu_n}(pred) \cdot phi_{relu_n}(pred)^T - phi_{relu_n}(target) \cdot phi_{relu_n}(target)^T \|_F^2
    relu_n: 2           #which conv-relu block number to get. the lower - the finer features are extracted, the higher - the more abstract
    content: 'mse'      #content loss
  # GPU devices to use (e.g., [0] for single GPU, [0, 1] for multiple GPUs)
  gpus: [4]
  checkpoint: null
  # Early stopping configuration
  early_stopping: "val/mse:aggregate"
  min_delta: 1e-4
  precision: "bf16-mixed"
  # Seed for reproducibility
  seed: 123