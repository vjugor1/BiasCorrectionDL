base_dir: "/app/data/experiments/downscaling-ERA-ERA"

data:
  era5_low_res_dir: "/app/data/ClimateLearn/processed/weatherbench/era5/5.625deg"
  era5_high_res_dir: "/app/data/ClimateLearn/processed/weatherbench/era5/2.8125deg"
  subsample: 1
  batch_size: 256 #64
  buffer_size: 10000
  num_workers: 4
  scale_factor: 2
  # Available variables: 
  # "land_sea_mask", "orography", "latitude", "toa_incident_solar_radiation",
  # "2m_temperature", "10m_u_component_of_wind", "10m_v_component_of_wind",
  # "geopotential", "temperature", "relative_humidity", "specific_humidity",
  # "u_component_of_wind", "v_component_of_wind"
  in_variables: ["2m_temperature", "10m_u_component_of_wind", "10m_v_component_of_wind", "land_sea_mask", "orography", "lattitude"]
  # Output variables to predict. Options are: "2m_temperature", "geopotential_500", "temperature_850"
  out_variables: ["2m_temperature", "10m_u_component_of_wind", "10m_v_component_of_wind"]

model:
  # Model architecture options: "resnet", "unet", "vit", "samvit", "ynet", "deepsd", "diffusion", "gan"
  architecture: "gan"
  # Upsampling method options: "bilinear", "bicubic", "unet_upsampling", "unet_upsampling_bilinear", "none"
  # NOTE: Some models (e.g. ynet) do not support input upsampling, so they need this parameter set "none"
  upsampling: "none"

training:
  summary_depth: 1
  max_epochs: 500
  patience: 100
  learning_rate: 3e-4
  warmup_epochs: 100
  warmup_start_lr: 1e-8
  eta_min: 1e-8
  weight_decay: 1e-5
  beta_0: 0.9
  beta_1: 0.99
  # GPU devices to use (e.g., [0] for single GPU, [0, 1] for multiple GPUs)
  gpus: [0]
  wmse: 5
  checkpoint: null
  # Early stopping configuration
  early_stopping: "val/mse:aggregate"
  min_delta: 1e-4
  precision: "bf16-mixed" 
  # Seed for reproducibility
  seed: 777