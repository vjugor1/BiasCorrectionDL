base_dir: "/app/data/experiments/downscaling-CMIP-CMIP"

data:
  low_res_dir: "/app/data/processed/cmip6-cmip6/LR"
  high_res_dir: "/app/data/processed/cmip6-cmip6/HR"
  subsample: 1
  batch_size: 4
  buffer_size: 2000
  num_workers: 2
  # Available variables: 
  # "air_temperature", "u_component_of_wind", "v_component_of_wind", "surface_pressure", "precipitation", "orography", "land_sea_mask", "latitude", "specific_humidity", "cloud_cover", "upward_heat_flux", "moisture_in_soil"
  # "air_temperature", "u_component_of_wind", "v_component_of_wind", "precipitation", "pressure_sea_level", "specific_humidity", "cloud_cover", "upward_heat_flux", "moisture_in_soil"
  in_variables: ["air_temperature", "u_component_of_wind", "v_component_of_wind", "precipitation", "pressure_sea_level", "specific_humidity", "cloud_cover", "upward_heat_flux", "moisture_in_soil"]
  # Output variables to predict. Options are: "2m_temperature", "10m_u_component_of_wind", "10m_v_component_of_wind", "surface_pressure", "total_precipitation"
  out_variables: ["air_temperature", "u_component_of_wind", "v_component_of_wind", "precipitation"]

model:
  # Model architecture options: "resnet", "unet", "vit", "samvit", "ynet", "deepsd", "diffusion"
  architecture: "esrgan"
  # Upsampling method options: "bilinear", "bicubic", "unet_upsampling", "unet_upsampling_bilinear", "none"
  # NOTE: Some models (ynet, deepsd, diffusion, dcgan, edrn) do not support input upsampling, so they need this parameter set "none"
  upsampling: "none"

training:
  summary_depth: 1
  max_epochs: 200
  patience: 15
  learning_rate: 3e-4
  weight_decay: 1e-5
  betas: [0.9, 0.99]
  warmup_epochs: 5
  train_loss: ["mse"]
  perceptual_hp:        #works only with single gpu; total loss is content(pred,target) + feature_coeff * feature_loss + gram_coeff * gram_loss
    feature_coeff: 0.01 #coefficient before \| phi_{relu_n}(pred) - phi_{relu_n}(target)) \|_2^2
    gram_coeff: 0.01    #coefficient before \| phi_{relu_n}(pred) \cdot phi_{relu_n}(pred)^T - phi_{relu_n}(target) \cdot phi_{relu_n}(target)^T \|_F^2
    relu_n: 2           #which conv-relu block number to get. the lower - the finer features are extracted, the higher - the more abstract
    content: 'mse'      #content loss
  # GPU devices to use (e.g., [0] for single GPU, [0, 1] for multiple GPUs)
  gpus: [0]
  checkpoint: null
  # Early stopping configuration
  early_stopping: "val/mse:aggregate"
  min_delta: 1e-4
  precision: "bf16-mixed"
  # Seed for reproducibility
  seed: 42